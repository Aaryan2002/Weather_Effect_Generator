{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678a2f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageEnhance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f9f81d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_type = \"DPT_Large\"     # MiDaS v3 - Large     (highest accuracy, slowest inference speed)\n",
    "#model_type = \"DPT_Hybrid\"   # MiDaS v3 - Hybrid    (medium accuracy, medium inference speed)\n",
    "# model_type = \"MiDaS_small\"  # MiDaS v2.1 - Small   (lowest accuracy, highest inference speed)\n",
    "\n",
    "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d665cc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
    "transform = midas_transforms.small_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959a5611",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp =  np.random.randint(low=0, high=255, size=(640,640, 3))\n",
    "out = transform(inp)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1454f8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e4ebd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "midas.eval();\n",
    "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
    "\n",
    "if model_type == \"DPT_Large\" or model_type == \"DPT_Hybrid\":\n",
    "    transform = midas_transforms.dpt_transform\n",
    "else:\n",
    "    transform = midas_transforms.small_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8efef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDisparityMap(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    input_batch = transform(img)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prediction = midas(input_batch)\n",
    "\n",
    "        prediction = torch.nn.functional.interpolate(\n",
    "            prediction.unsqueeze(1),\n",
    "            size=img.shape[:2],\n",
    "            mode=\"bicubic\",\n",
    "            align_corners=False,\n",
    "        ).squeeze()\n",
    "\n",
    "    return prediction.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1adf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = \"b1cd1e94-26dd524f\"\n",
    "image_path = f\"data/rgb/{img_name}.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95d8925",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp_map = getDisparityMap(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f55203a",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_min = disp_map.min()\n",
    "depth_max = disp_map.max()\n",
    "normalized_depth = 255 * (disp_map - depth_min) / (depth_max - depth_min)\n",
    "normalized_depth *= 3\n",
    "\n",
    "right_side = np.repeat(np.expand_dims(normalized_depth, 2), 3, axis=2) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75100587",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray((255-right_side).astype(np.uint8)).save(f\"{img_name}_disp.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83d597c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04640804",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"b1ee702d-4a193906\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576339a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### kitti\n",
    "baseline = 0.54\n",
    "focal = 707.09\n",
    "img_scale = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d919707",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = sorted(Path(\"data/rgb/\").glob(\"*.jpg\"))\n",
    "for path in img_paths:\n",
    "    disp = getDisparityMap(str(path))\n",
    "    disp[disp<0]=0\n",
    "    disp = disp + 1e-3\n",
    "    depth = 0.54*721/(disp*img_scale)\n",
    "    np.save(\"data/depth/\"+path.stem, depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e8acfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = getDisparityMap(\"b1d3907b-2278601b-enhance.jpg\")\n",
    "disp[disp<0]=0\n",
    "disp = disp + 1e-3\n",
    "depth = 0.54*721/(disp*img_scale)\n",
    "np.save(\"b1d3907b-2278601b-enhance\", depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bca0413",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = getDisparityMap(\"b1d7b3ac-5744370e.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dae2ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bits = 2\n",
    "\n",
    "if not np.isfinite(depth).all():\n",
    "    depth=np.nan_to_num(depth, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    print(\"WARNING: Non-finite depth values present\")\n",
    "\n",
    "depth_min = depth.min()\n",
    "depth_max = depth.max()\n",
    "\n",
    "max_val = (2**(8*bits))-1\n",
    "\n",
    "if depth_max - depth_min > np.finfo(\"float\").eps:\n",
    "    out = max_val * (depth - depth_min) / (depth_max - depth_min)\n",
    "else:\n",
    "    out = np.zeros(depth.shape, dtype=depth.dtype)\n",
    "\n",
    "out = cv2.applyColorMap(np.uint8(out), cv2.COLORMAP_INFERNO)\n",
    "cv2.imwrite(\"disp.png\", out.astype(\"uint16\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba82ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_side_by_side(image, depth, grayscale):\n",
    "    \"\"\"\n",
    "    Take an RGB image and depth map and place them side by side. This includes a proper normalization of the depth map\n",
    "    for better visibility.\n",
    "    Args:\n",
    "        image: the RGB image\n",
    "        depth: the depth map\n",
    "        grayscale: use a grayscale colormap?\n",
    "    Returns:\n",
    "        the image and depth map place side by side\n",
    "    \"\"\"\n",
    "    depth_min = depth.min()\n",
    "    depth_max = depth.max()\n",
    "    normalized_depth = 255 * (depth - depth_min) / (depth_max - depth_min)\n",
    "    normalized_depth *= 3\n",
    "\n",
    "    right_side = np.repeat(np.expand_dims(normalized_depth, 2), 3, axis=2) / 3\n",
    "    if not grayscale:\n",
    "        right_side = cv2.applyColorMap(np.uint8(right_side), cv2.COLORMAP_INFERNO)\n",
    "\n",
    "    if image is None:\n",
    "        return right_side\n",
    "    else:\n",
    "        return np.concatenate((image, right_side), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a721a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.cvtColor(cv2.imread(\"b1d7b3ac-5744370e.jpg\"), cv2.COLOR_BGR2RGB).astype(float) / 255.0\n",
    "original_image_bgr = np.flip(img, 2)\n",
    "content = create_side_by_side(original_image_bgr*255, depth, True)\n",
    "cv2.imwrite(\"test.png\", content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1c9858",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
