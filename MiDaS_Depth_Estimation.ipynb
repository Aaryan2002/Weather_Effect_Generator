{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678a2f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageEnhance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616d11d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_depth_estimation_model(model_name:str):\n",
    "    assert model_name in [\"DPT_Large\", \"DPT_Hybrid\", \"MiDaS_small\"]\n",
    "    \n",
    "    midas = torch.hub.load(\"intel-isl/MiDaS\", model_name)\n",
    "    midas.eval();\n",
    "    \n",
    "    \n",
    "    midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
    "    if model_type == \"DPT_Large\" or model_type == \"DPT_Hybrid\":\n",
    "        transform = midas_transforms.dpt_transform\n",
    "    else:\n",
    "        transform = midas_transforms.small_transform\n",
    "    return midas, transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8efef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDisparityMap(model, transform, img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    input_batch = transform(img)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prediction = midas(input_batch)\n",
    "\n",
    "        prediction = torch.nn.functional.interpolate(\n",
    "            prediction.unsqueeze(1),\n",
    "            size=img.shape[:2],\n",
    "            mode=\"bicubic\",\n",
    "            align_corners=False,\n",
    "        ).squeeze()\n",
    "\n",
    "    return prediction.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576339a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### kitti\n",
    "baseline = 0.54\n",
    "focal = 721.09\n",
    "img_scale = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d919707",
   "metadata": {},
   "outputs": [],
   "source": [
    "midas, midas_transform = get_depth_estimation_model(model_name=\"DPT_Large\")\n",
    "\n",
    "img_paths = sorted(Path(\"data/rgb/\").glob(\"*.jpg\"))\n",
    "for path in img_paths:\n",
    "    disp = getDisparityMap(midas, midas_transform, str(path))\n",
    "    disp[disp<0]=0\n",
    "    disp = disp + 1e-3\n",
    "    depth = baseline*focal/(disp*img_scale)\n",
    "    np.save(\"data/depth/\"+path.stem, depth)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
